---
title: "Gina's fish personality"
output: pdf_document
date: "2023-05-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background information

This project evaluates the effect of BMAA (a cyanotoxin) on fathead minnow behavior. Young fish were grouped in 3 treatment conditions: control (no BMAA exposure), T5 (low BMAA exposure) and T25 (moderate BMAA exposure). Behavioral responses to an open-field test were then recorded at 8 time points across development. Ethovision was used to record behavior during the open-field test and resulted in many different variables that could represent different aspects of personality. Additionally, embryos were test once for burst activity.

Our main questions with these data are:
1. Are the behaviors recorded during the open field test reflective of underlying personality traits? To test this we will evaluate the repeatability of each behavior across the 8 time points.
2. How does BMAA exposure affect behavior in the open field test? To test this we will compare performance among treatment groups.


## Methods

We first need to determine the relationships among the variables recorded by Ethovision.

```{r variables}
etho = read.csv(url("https://raw.githubusercontent.com/ginalamka/Personality_BMAA/main/EthoData_updated.csv?token=GHSAT0AAAAAACB372QA37AYRBA76MHRCWXSZD7LT4Q"), header=T, sep=",", stringsAsFactors=F)

##How correlated are the variables?
#Create dataframe with just numeric/integer values
etho.corr = etho[,-c(1:7)]
etho.corr$MeanTimeZ2 = as.numeric(etho.corr$MeanTimeZ2)
etho.corr$LatencyZ2 = as.numeric(etho.corr$LatencyZ2)
etho.corr=etho.corr[-which(is.na(etho.corr$MeanTimeZ2)),] #There are some missing data that may need to be changed to ceiling values? For now, we will ignore those.


library(Hmisc)
library(corrplot)
#Dataframe should be a matrix. 
cor = rcorr(as.matrix(etho.corr))
corrplot(cor$r,type = "upper",p.mat=cor$P, sig.level=0.05, insig = "blank",diag=F) #lots of variables correlated to differing degrees




##Do correlated variables load on PCs to suggest personality axes?
#calc principal components
pca <- prcomp(etho.corr, scale=TRUE)

#need to reverse the signs
pca$rotation <- -1*pca$rotation

#calc total variance explained by each princ component
pca$sdev^2/sum(pca$sdev^2) # first 5 PCs account for 72ish % of variance in data

#display principal components
loadings = data.frame(pca$rotation[1:25,1:5]) #all 25 variables, first 5 PCs
loadings = loadings[order(-abs(loadings$PC1), -abs(loadings$PC2), -abs(loadings$PC3), -abs(loadings$PC4), -abs(loadings$PC5)),]

#create biplot to visualize
biplot(pca$x[, 1:2], pca$rotation[, 1:2], cex=1)

```

## Interpreting the loadings (From http://strata.uga.edu/8370/lecturenotes/principalComponents.html): 
Because the sum of the squares of all loadings for an individual principal component must sum to one, we can calculate what the loadings would be if all variables contributed equally to that principal component. Any variable that has a larger loading than this value contributes more than one variableâ€™s worth of information and would be regarded as an important contributor to that principal component.

We have 25 variables, the square root of the value if each variable contributed equally (1/25) is 0.2. So, variable loadings that are greater than 0.2 contribute a larger than expected amount to the PC.

# PC1 - fast vs slow-exploring
The following variables have large, negative loadings: MeanVel, TotDist, FreqTransZ2.Z1, Mean.Activ, Tot.Act, FreqTransZ1.Z2, Mean.Mobility, FreqZ2.
The following variables have large, positive loadings (and so have an opposite effect of PC1): VarTurnAngle, LatencyZ2, LatencyZ2360.

# PC2
Large, negative loadings: CumDur.Z1, CumDurZ1
Large, positive loadings: CumDur.Z2, CumDurZ2, MeanTimeZ2, MeanTimeZ2Zero, FreqZ2


```{r variables by age}
#### Do PCAs for each age
#keep track of variance and loadings for each PC at each age with data frame
#Age categories: 21  49  77  14 105  133 161 189
etho$Age[which(etho$Age == 15)]<-14

for(i in unique(etho$Age)){
  temp = etho[etho$Age==i,]
  temp$MeanTimeZ2 = as.numeric(temp$MeanTimeZ2)
  temp$LatencyZ2 = as.numeric(temp$LatencyZ2)
  temp=temp[-which(is.na(temp$MeanTimeZ2)),]
  pca_i <- prcomp(temp[,8:32], scale=TRUE)
  pca_i$rotation <- -1*pca_i$rotation
  var = data.frame(pca_i$sdev^2/sum(pca_i$sdev^2))
  rot = data.frame(pca_i$rotation[1:25,1])
  colnames(var) = i
  colnames(rot) = i
  if(i==21){
    vars = var
    rots = rot
  } else{
    vars = cbind(vars, var)
    rots = cbind(rots, rot)
  }
}
#Range of variance accounted for by PC1 is 25-31%
#Range of PC2 is 16-25%
vars$PC = row.names(vars)
scree.plot = gather(vars, age, value, "21":"189",factor_key =F)
ggplot(scree.plot, aes(x = as.numeric(PC), y = (value)*100, color = as.factor(age))) + 
  theme_bw() +
  geom_line() +
  geom_hline(yintercept=4) #the amount of variance each variable would contribute if all contributed the same amount: 1/25*100


###do PC loadings stay the same across ages? Spaghetti plot:
library(tidyr)
library(ggplot2)
rots$variables = row.names(rots)
plot.data = gather(rots, age, value, "21":"189", factor_key = F)
ggplot(plot.data, aes(x = as.numeric(age), y = abs(value), color = variables)) +
  geom_line() +
  theme_bw()

```

## PC conclusions
The PC loadings are too diffuse and inconsistent across time points. We will move forward with candidate variables for 3 personality traits, chosen based on the correlation matrix.



# Variables:
1. Exploration = Angular Velocity. The relative turn angle / time difference ; degrees per second; can be + or -. Measures the speed of change in direction of movement - used to assess turn bias or circular tendency and abnormalities of behavior. NOTE - turn angle is sensitive to small movements of body points. if distance moved is very small, turn angle can get high, unrealistic values (additionally, consecutive turns can have high values). To combat this, let's scale distance moved.

    - Relative turn angle is the signed angle of each turn. As such, when summary statistics are done, some of the angles cancel each other out and it is hard/confusing to interpret these numbers. Relative turn angle informs the primary direction of turns individuals make (rather than how many turns vs how straight is the path)
    - As such, we may consider using another variable like cumulative duration in the center (see boldness)

2. Activity = Mobility. The percentage of pixel change between current sample and previous sample *detected in the subject only* ; ranges from 0 - 100%. NOTE - mobility depends on size of subject only, not on arena size. small fish results in small number of pixels that change, therefore small movements results in high change

3. Boldness = Cumulative duration in the center (count or proportion) OR Latency to enter the center (see exploration).


## Exploration
```{r turning angle rpt}
etho = read.csv("/Users/kelseymccune/Documents/GitHub/Personality_BMAA/EthoData_updated.csv", header=T, sep=",", stringsAsFactors=F)

#test fit of Gaussian distribution
library(ggpubr)
ggqqplot(log(abs(scale(etho$MeanAngVel, center = T, scale = T))))
shapiro.test(log(abs(scale(etho$MeanAngVel, center = T, scale = T))))

library(lme4)
ta1 = lmer(log(abs(scale(MeanAngVel, center = T, scale = T))) ~ Treatment + Age + (1|FishName) + (1|Clutch) + (1|Paternity), data = etho)
summary(ta1) #fit is singular because clutch random effect accounts for 0 variance
ggqqplot(ta1@u)
plot(ta1)

# Maybe MeanTurnAngle will fit better? Why do values range from -16 to +16? Description of this variable on pg. 63 of Manual pdf
# Do we have absolute or relative mean turn angle/angular velocity?
ta2 = lmer(log(abs(MeanTurnAngle)) ~ Treatment + Age + (1|FishName) + (1|Clutch) + (1|Paternity), data = etho)
summary(ta2)
ggqqplot(ta2@u)
plot(ta2)

```


## Rethinking exploration

The data for turning angle are summarized from Relative turning angle (where the sign of the turn is taken in to account). This means that mean of turning angle within a trial are not reflective of the number and degree of turns individuals make because turns in different directions cancel out.

We could use Variance in Turning Angle to illustrate the predictability with which an individual turns, but variance is also calculated based on the mean which does not have much significance for exploration. Large numbers mean that turning angle is very different from the mean, small numbers mean the turning angle is similar to the mean.

Alternatively, we could pick different variables. For one, we could say Duration in the Center is representative of exploration and Latency to enter the Center is representative of boldness. Or we could say Frequency of Zone Alterations is a measure of exploration (actually no because they could be crossing zones repeatedly in a very small amount of space). Although it could seem like another measure of activity, it is not very correlated with Mean Mobility (0.24). This variable does look like it varies by arena size, so we would need to account for that in some way - maybe include an offset for average body size at each age, or arena size.


```{r exploration alternatives}
library(ggplot2)
ggplot(etho[which(etho$Treatment == "0"),], aes(x = FishName, y = VarTurnAngle)) +
  #facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic()
ggplot(etho[which(etho$Treatment == "0"),], aes(x = FishName, y = CumDur.Z2/100)) +
  #facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic()
#one outlier individual in Control that crossed zones a lot
ggplot(etho[which(etho$Treatment == "0"),], aes(x = FishName, y = LatencyZ2360)) +
  #facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic()
#the ceiling values could make it hard to fit these data


```


## Boldness
Time spent in the middle is our measure of boldness. The variables are the proportion of time spent in the middle (out of trial time = 360 sec) or the actual number of seconds spent in the middle zone. It is difficult to find a well-fitting model family or transformation of the proportion data. Negative binomial fits well to the proportion data. A poisson model with an observation-level random effect fits well to the count data.

```{r boldness-cumulative duration in the middle}
etho = read.csv("/Users/kelseymccune/Documents/GitHub/Personality_BMAA/EthoData_updated.csv", header=T, sep=",", stringsAsFactors=F)
etho$trial.time = 360
etho$OLRE = seq_len(nrow(etho)) #column with observation-level random effect
etho$scale.age = scale(etho$Age, scale = T, center = T)
etho$FishName = as.factor(etho$FishName)
etho$Treatment = as.factor(etho$Treatment)

library(DHARMa)
library(lme4)

# I tried binomial, poisson and negative binomial. Negative binomial and Poisson with Observation-level random effect to account for overdispersion are the only models that passed all model assumption checks.
#Negative Binomial:
simulationOutput <- simulateResiduals(fittedModel = glmer.nb(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch), data=etho, control=glmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=2e5))), n=250) #add optimizer because otherwise it fails to converge with interaction term
# fit is singular with Paternity included

#Poisson with Observation-level random effect to account for overdispersion:
simulationOutput <- simulateResiduals(fittedModel = glmer(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|OLRE), family = poisson, data=etho), n=500) #isSingular warning because of Paternity & Clutch

plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor. 
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation.
#p.nb= 0.19, p.pois = 0.14 
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p>0.05.
#p.nb < 0.01 (10% are zeros), p.pois = 0.88  
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05.
#p.nb = 0.02, p.pois = 0.49
plot(simulationOutput)



#### Best fit is the Poisson regression on percent time in middle with the OLRE. ####


# Double check which variables to include in accordance with above simulation results:
b1 = glmer(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch) + (1|Paternity) + (1|OLRE), family = poisson, data=etho, control=glmerControl(optimizer="bobyqa", #add optimizer because otherwise it fails to converge
                                 optCtrl=list(maxfun=2e5))) # full model
theta <- getME(b1, "theta")
diag.element <- getME(b1, "lower")==0
which(theta[diag.element]<3e-5)
#Fit is singular because of clutch and paternity

b2 = glmer(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|OLRE), family = poisson, data=etho)
anova(b1,b2) # no difference, proceed with model 2 (results did not change with or without optimizer)

b3 = glmer(round(CumDur.Z2) ~ Treatment + scale.age + (1|FishName) + (1|OLRE), family = poisson, data=etho) # no interaction
anova(b2,b3) # b2 is a significantly better fit. Use b2 in rpt function.

#### rptR package for repeatability estimate
rptB = rpt(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|OLRE), datatype = "Poisson", data=etho, grname = "FishName", nboot = 100, npermut = 100) # model fails to converge with the OLRE ðŸ¤¦
rptB


#### MCMCglmm instead of rptR for repeatability estimate
library(MCMCglmm)
prior = list(R=list(R1=list(V=1,nu=0.002)), G=list(G1=list(V=1,nu=0.002))) #weak priors
mc1 = MCMCglmm(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age, random = ~FishName, family = "poisson", data = etho,
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
plot(mc1) #all chains look good
autocorr(mc1$Sol) #Did fixed effects converge? (<0.1)? 
autocorr(mc1$VCV)
repeata <- mc1$VCV[,"FishName"]/(mc1$VCV[,"FishName"]+mc1$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeata) # Repeatability: 0.12
var(repeata) # 0.001
posterior.mode(repeata) # 0.12
HPDinterval(repeata, 0.95) # 0.06 - 0.19

##### permute the data so fish behavior is random to test the significance of 0.12 repeatability value #####


ggplot(etho[which(etho$Treatment == "0"),], aes(x = FishName, y = round(CumDur.Z2))) +
  #facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic()

```


If we need to use cumulative duration in the middle as our measure of exploration, we can instead use latency to enter the middle as our measure of boldness.
```{r boldness-latency to enter the middle}


#Poisson with Observation-level random effect to account for overdispersion:
simulationOutput <- simulateResiduals(fittedModel = glmer(round(LatencyZ2360) ~ Treatment + scale(Age, center = T, scale = T) + (1|FishName) , family = poisson, data=etho), n=500) #model failed to converge with interaction effect. isSingular warning because of Paternity & Clutch





```

