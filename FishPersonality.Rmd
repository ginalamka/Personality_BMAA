---
title: "Gina's fish personality"
output: pdf_document
date: "2023-05-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background information

This project evaluates the effect of BMAA (a cyanotoxin) on fathead minnow behavior. Young fish were grouped in 3 treatment conditions: control (no BMAA exposure), T5 (low BMAA exposure) and T25 (moderate BMAA exposure). Behavioral responses to an open-field test were then recorded at 8 time points across development. Ethovision was used to record behavior during the open-field test and resulted in many different variables that could represent different aspects of personality. Additionally, embryos were tested once for burst activity.

Our main questions with these data are:
1. Are the behaviors recorded during the open field test reflective of underlying personality traits or a behavioral syndrome? To test this we will evaluate the repeatability of each behavior across the 8 time points.
2. How does BMAA exposure affect behavior in the open field test? To test this we will compare performance among treatment groups.


# Methods

We first need to determine the relationships among the variables recorded by Ethovision.

```{r variables}
etho = read.csv(url("https://raw.githubusercontent.com/ginalamka/Personality_BMAA/main/EthoData_updated.csv?token=GHSAT0AAAAAACUS76MRXKHDLZE5YYRHYN4GZUO5AJA"), header=T, sep=",", stringsAsFactors=F)
etho$Age[which(etho$Age == 15)]<-14

##How correlated are the variables?
#Create dataframe with just numeric/integer values
etho.corr = etho[,-c(1:7)]
etho.corr$MeanTimeZ2 = as.numeric(etho.corr$MeanTimeZ2)
etho.corr$LatencyZ2 = as.numeric(etho.corr$LatencyZ2)
etho.corr=etho.corr[-which(is.na(etho.corr$MeanTimeZ2)),] #There are some missing data that may need to be changed to ceiling values? For now, we will ignore those.


library(Hmisc)
library(corrplot)
#Dataframe should be a matrix. 
cor = rcorr(as.matrix(etho.corr))
corrplot(cor$r,type = "upper",p.mat=cor$P, sig.level=0.05, insig = "blank",diag=F) #lots of variables correlated to differing degrees


```


# PCA
```{r pca}
##Do correlated variables load on PCs to suggest personality axes?
#calc principal components
# pca <- prcomp(etho.corr, scale=TRUE)
# 
# #need to reverse the signs
# pca$rotation <- -1*pca$rotation
# 
# #calc total variance explained by each princ component
# pca$sdev^2/sum(pca$sdev^2) # first 5 PCs account for 72ish % of variance in data
# 
# #display principal components
# loadings = data.frame(pca$rotation[1:25,1:5]) #all 25 variables, first 5 PCs
# loadings = loadings[order(-abs(loadings$PC1), -abs(loadings$PC2), -abs(loadings$PC3), -abs(loadings$PC4), -abs(loadings$PC5)),]
# 
# #create biplot to visualize
# biplot(pca$x[, 1:2], pca$rotation[, 1:2], cex=1)

# for(i in unique(etho$Age)){
#   temp = etho[etho$Age==i,]
#   temp$MeanTimeZ2 = as.numeric(temp$MeanTimeZ2)
#   temp$LatencyZ2 = as.numeric(temp$LatencyZ2)
#   temp=temp[-which(is.na(temp$MeanTimeZ2)),]
#   pca_i <- prcomp(temp[,8:32], scale=TRUE)
#   pca_i$rotation <- -1*pca_i$rotation
#   var = data.frame(pca_i$sdev^2/sum(pca_i$sdev^2))
#   rot = data.frame(pca_i$rotation[1:25,1])
#   colnames(var) = i
#   colnames(rot) = i
#   if(i==21){
#     vars = var
#     rots = rot
#   } else{
#     vars = cbind(vars, var)
#     rots = cbind(rots, rot)
#   }
# }
# #Range of variance accounted for by PC1 is 25-31%
# #Range of PC2 is 16-25%
# vars$PC = row.names(vars)
# scree.plot = gather(vars, age, value, "21":"189",factor_key =F)
# ggplot(scree.plot, aes(x = as.numeric(PC), y = (value)*100, color = as.factor(age))) + 
#   theme_bw() +
#   geom_line() +
#   geom_hline(yintercept=4) #the amount of variance each variable would contribute if all contributed the same amount: 1/25*100
# 
# 
# ###do PC loadings stay the same across ages? Spaghetti plot:
# library(tidyr)
# library(ggplot2)
# rots$variables = row.names(rots)
# plot.data = gather(rots, age, value, "21":"189", factor_key = F)
# ggplot(plot.data, aes(x = as.numeric(age), y = abs(value), color = variables)) +
#   geom_line() +
#   theme_bw()
```

## Interpreting the loadings (From http://strata.uga.edu/8370/lecturenotes/principalComponents.html): 
Because the sum of the squares of all loadings for an individual principal component must sum to one, we can calculate what the loadings would be if all variables contributed equally to that principal component. Any variable that has a larger loading than this value contributes more than one variableâ€™s worth of information and would be regarded as an important contributor to that principal component.

We have 25 variables, the square root of the value if each variable contributed equally (1/25) is 0.2. So, variable loadings that are greater than 0.2 contribute a larger than expected amount to the PC.

### PC1 - fast vs slow-exploring
The following variables have large, negative loadings: MeanVel, TotDist, FreqTransZ2.Z1, Mean.Activ, Tot.Act, FreqTransZ1.Z2, Mean.Mobility, FreqZ2.
The following variables have large, positive loadings (and so have an opposite effect of PC1): VarTurnAngle, LatencyZ2, LatencyZ2360.

### PC2
Large, negative loadings: CumDur.Z1, CumDurZ1
Large, positive loadings: CumDur.Z2, CumDurZ2, MeanTimeZ2, MeanTimeZ2Zero, FreqZ2


## PC conclusions
The PC loadings are too diffuse and inconsistent across time points. We will move forward with candidate variables for 3 personality traits, chosen based on the correlation matrix.


```{r variables by age}

#### Variables that relate to arena size change with age
boxplot(TotDist ~ Age, data = etho)
boxplot(MeanMeander ~ Age, data = etho)


```



## Variables:
1. Exploration = Cumulative duration in the center (percent) **"CumDur.Z2"**
*Not used:*
  *- Angular Velocity. The relative turn angle / time difference ; degrees per second; can be + or -. Measures the speed of change in direction of movement - used to assess turn bias or circular tendency and abnormalities of behavior. NOTE - turn angle is sensitive to small movements of body points. if distance moved is very small, turn angle can get high, unrealistic values (additionally, consecutive turns can have high values). To combat this, let's scale distance moved.*
  *- Relative turn angle is the signed angle of each turn. As such, when summary statistics are done, some of the angles cancel each other out and it is hard/confusing to interpret these numbers. Relative turn angle informs the primary direction of turns individuals make (rather than how many turns vs how straight is the path)*
*As such, we may consider using another variable like cumulative duration in the center (see boldness)*

2. Activity = Mobility. The percentage of pixel change between current sample and previous sample *detected in the subject only* ; ranges from 0 - 100%. NOTE - mobility depends on size of subject only, not on arena size. small fish results in small number of pixels that change, therefore small movements results in high change **"Mean.Mobility"**

3. Boldness = Latency to enter the center **"LatencyZ2360"**


# Repeatability Results

## Exploration - OLD - Mean angular velocity
```{r turning angle rpt}
#etho = read.csv("/Users/kelseymccune/Documents/GitHub/Personality_BMAA/EthoData_updated.csv", header=T, sep=",", stringsAsFactors=F)

#test fit of Gaussian distribution
library(ggpubr)
ggqqplot(log(abs(scale(etho$MeanAngVel, center = T, scale = T))))
shapiro.test(log(abs(scale(etho$MeanAngVel, center = T, scale = T)))) # not normal

library(lme4)
ta1 = lmer(log(abs(scale(MeanAngVel, center = T, scale = T))) ~ Treatment + Age + (1|FishName) + (1|Clutch) + (1|Paternity), data = etho)
summary(ta1) #fit is singular because clutch random effect accounts for 0 variance
ggqqplot(ta1@u)
plot(ta1)

# Maybe MeanTurnAngle will fit better? Why do values range from -16 to +16? Description of this variable on pg. 63 of Manual pdf
# Do we have absolute or relative mean turn angle/angular velocity?
ta2 = lmer(log(abs(MeanTurnAngle)) ~ Treatment + Age + (1|FishName) + (1|Clutch) + (1|Paternity), data = etho)
summary(ta2)
ggqqplot(ta2@u)
plot(ta2)

```

### Rethinking exploration

The data for turning angle are summarized from Relative turning angle (where the sign of the turn is taken in to account). This means that mean of turning angle within a trial are not reflective of the number and degree of turns individuals make because turns in different directions cancel out.

We could use Variance in Turning Angle to illustrate the predictability with which an individual turns, but variance is also calculated based on the mean which does not have much significance for exploration. Large numbers mean that turning angle is very different from the mean, small numbers mean the turning angle is similar to the mean.

Alternatively, we could pick different variables. For one, we could say Duration in the Center is representative of exploration and Latency to enter the Center is representative of boldness. Or we could say Frequency of Zone Alterations is a measure of exploration (actually no because they could be crossing zones repeatedly in a very small amount of space). Although it could seem like another measure of activity, it is not very correlated with Mean Mobility (0.24). This variable does look like it varies by arena size, so we would need to account for that in some way - maybe include an offset for average body size at each age, or arena size.

```{r exploration alternatives}
library(ggplot2)
ggplot(etho[which(etho$Treatment == "0"),], aes(x = FishName, y = VarTurnAngle)) +
  #facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic()
ggplot(etho[which(etho$Treatment == "0"),], aes(x = FishName, y = CumDur.Z2/100)) +
  #facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic()
#one outlier individual in Control that crossed zones a lot
ggplot(etho[which(etho$Treatment == "0"),], aes(x = FishName, y = LatencyZ2360)) +
  #facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic()
#the ceiling values could make it hard to fit these data


```

Time spent in the middle can be the proportion of time spent in the middle (out of trial time = 360 sec) or the actual number of seconds spent in the middle zone. It is difficult to find a well-fitting model family or transformation of the proportion data. Negative binomial fits well to the proportion data. A poisson model with an observation-level random effect fits well to the count data.

```{r exploration-cumulative duration in the middle}
#etho = read.csv("/Users/kelseymccune/Documents/GitHub/Personality_BMAA/EthoData_updated.csv", header=T, sep=",", stringsAsFactors=F)
etho$trial.time = 360
etho$OLRE = seq_len(nrow(etho)) #column with observation-level random effect
etho$scale.age = scale(etho$Age, scale = T, center = T)
etho$FishName = as.factor(etho$FishName)
etho$Treatment = as.factor(etho$Treatment)

library(DHARMa)
library(lme4)

# I tried binomial, poisson and negative binomial. Negative binomial and Poisson with Observation-level random effect to account for overdispersion are the only models that passed all model assumption checks.
#Negative Binomial:
simulationOutput <- simulateResiduals(fittedModel = glmer.nb(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch), data=etho, control=glmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=2e5))), n=250) #add optimizer because otherwise it fails to converge with interaction term
# fit is singular with Paternity included

#Poisson with Observation-level random effect to account for overdispersion:
simulationOutput <- simulateResiduals(fittedModel = glmer(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|OLRE), family = "poisson", data=etho), n=500) #isSingular warning because of Paternity & Clutch

plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor. 
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation.
#p.nb= 0.19, p.pois = 0.14 
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p>0.05.
#p.nb < 0.01 (10% are zeros), p.pois = 0.88  
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05.
#p.nb = 0.02, p.pois = 0.49
plot(simulationOutput)



#### Best fit is the Poisson regression on proportion of time in middle with the OLRE. ####


# Double check which variables to include in accordance with above simulation results:
e1 = glmer(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch) + (1|Paternity) + (1|OLRE), family = "poisson", data=etho, control=glmerControl(optimizer="bobyqa", #add optimizer because otherwise it fails to converge
                                 optCtrl=list(maxfun=2e5))) # full model
theta <- getME(b1, "theta")
diag.element <- getME(b1, "lower")==0
which(theta[diag.element]<3e-5)
#Fit is singular because of clutch and paternity

e2 = glmer(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|OLRE), family = "poisson", data=etho)
anova(e1,e2) # no difference, proceed with model 2 (results did not change with or without optimizer)

e3 = glmer(round(CumDur.Z2) ~ Treatment + scale.age + (1|FishName) + (1|OLRE), family = "poisson", data=etho) # no interaction
anova(e2,e3) # b2 is a significantly better fit. Use b2 in rpt function.

#### rptR package for repeatability estimate
library(rptR)
rptE = rpt(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName), datatype = "Poisson", data=etho, grname = "FishName", nboot = 100, npermut = 100) # Poisson models are automatically fit with an OLRE in the rptR package.
rptE # R = 0.10 but se = 0 and CI is 0.10-0.10 so something is wrong here.


#### MCMCglmm instead of rptR for repeatability estimate
#https://juliengamartin.github.io/wam_tuto/mcmcglmm-1.html
#examples in the lit: https://doi.org/10.1007/s00265-019-2637-4 ; https://doi.org/10.1111/jeb.13701
library(MCMCglmm)
prior = list(R=list(R1=list(V=1,nu=0.002)), G=list(G1=list(V=1,nu=0.002))) #weak priors
mc1 = MCMCglmm(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age, random = ~FishName, family = "poisson", data = etho,
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
plot(mc1) #all chains look good
autocorr(mc1$Sol) #Did fixed effects converge? (<0.1)? 
autocorr(mc1$VCV)
repeata <- mc1$VCV[,"FishName"]/(mc1$VCV[,"FishName"]+mc1$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeata) # Repeatability: 0.12
var(repeata) # 0.001
posterior.mode(repeata) # 0.13
HPDinterval(repeata, 0.95) # 0.06 - 0.19

##### permute the data so fish behavior is random to test the significance of 0.12 repeatability value #####
##### Takes a loooong time to run with 1000. 10 permutations takes ~10 min
results = rep(NA, 1000) 
for(i in 1:1000){
  tmp0 = data.frame("FishName" = etho$FishName[which(etho$Treatment=="0")], 
                    "Treatment"=etho$Treatment[which(etho$Treatment=="0")], 
                    "scale.age" = etho$scale.age[which(etho$Treatment=="0")], 
                    "CumDur.Z2" = sample(etho$CumDur.Z2[which(etho$Treatment=="0")],replace=F))
  tmp5 = data.frame("FishName" = etho$FishName[which(etho$Treatment=="5")], 
                    "Treatment"=etho$Treatment[which(etho$Treatment=="5")], 
                    "scale.age" = etho$scale.age[which(etho$Treatment=="5")],
                    "CumDur.Z2" = sample(etho$CumDur.Z2[which(etho$Treatment=="5")],replace=F))
  tmp25 = data.frame("FishName" = etho$FishName[which(etho$Treatment=="25")], 
                     "Treatment"=etho$Treatment[which(etho$Treatment=="25")], 
                     "scale.age" = etho$scale.age[which(etho$Treatment=="25")],
                     "CumDur.Z2" = sample(etho$CumDur.Z2[which(etho$Treatment=="25")],replace=F))
  tmp = rbind(tmp0,tmp5,tmp25)
  #tmp = data.frame("FishName" = etho$FishName,
    #               "Treatment" = etho$Treatment,
   #                "scale.age" = etho$scale.age,
     #              "CumDur.Z2" = sample(etho$CumDur.Z2, replace = F))
  m <- MCMCglmm(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age, random = ~FishName, family = "poisson", data = tmp,
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
  
  if(i==1){
    rpt <- m$VCV[,"FishName"]/(m$VCV[,"FishName"]+m$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval from the model
  } else{
    rpt = c(rpt, m$VCV[,"FishName"]/(m$VCV[,"FishName"]+m$VCV[,"units"])) #building by row all of the posterior estimates from each iteration of the permutation
  }
  results[i] = mean(rpt) #average repeatability estimate from each iteration of the permutation
}

hist(results) # average repeatability estimate from each iteration of the permutation, which randomizes choices within reversals
abline(v=0.12,col="red")
sum(results > 0.12)/1000 # probability the repeatability estimate from our actual data is greater than the repeatability estimates generated from the permutations which randomized the data

permut.results = results #rbind line hashtagged out in above permutations
permut.bytrt = results #line 295-298 hashtagged out in above permutations

permut.results = data.frame(permut.results)
colnames(permut.results) = "Repeatability"
permut.bytrt = data.frame(permut.bytrt)
colnames(permut.bytrt) = "Repeatability"
permut.results$type = "combined"
permut.bytrt$type = "by treatment"
permut = rbind(permut.results, permut.bytrt)

library(ggplot2)
library(ggbreak)
p <- ggplot(permut.bytrt, aes(x = Repeatability)) +
  geom_histogram(binwidth = 0.0001)+
  #facet_wrap(~type)+
  geom_vline(xintercept = 0.12, color = "red") +
  theme_classic() 
p+scale_x_break(c(0.0021,0.12), scales = "free", ticklabels = 0.12)
## I cannot get this plot to look how I want it to. The point is that no matter whether we permute across all data or permute data within treatment, the observed repeatability value is way larger than the permuted repeatability value.

```

### Exploration and treatment effects
```{r exploration & treatment}
summary(mc1)
# Main effects of treatment and age are not significant.
# interaction between treatment 5 and age is significant at B = -0.23, p = 0.05

# plot to visualize interaction effect
exp.plot = ggplot(etho, aes(x = Age, y = log(CumDur.Z2+1), color = Treatment))+
  geom_point(alpha = 0.7, size =3) +
  geom_smooth(method = "lm") +
  theme_bw() + 
  scale_x_continuous(limits=c(0,200),
                     breaks=c(14,21,49,77,105,133,161,189))+
  ylab("Cumulative duration in the center") + ggtitle("a) Exploration")
exp.plot
```
BMAA treatment was unrelated to the amount of time fish spent in the center of the arena. There was also no main effect of age. However, there was a significant interaction between treatment 5 and age. Relative to control fish and treatment 25 fish, fish in the treatment 5 group decreased the duration they spent in the center over time.


## Boldness

Because of the weirdness of the relative turn angle variable, we need to use cumulative duration in the middle as our measure of exploration. We instead use latency to enter the middle as our measure of boldness.

### Latency and survival models
Any latency variable, especially those with ceiling values, are most appropriately modeled using survival analysis. We can now calculate repeatability of this latency variable using survival models and a function Shinichi Nakagawa and I created in May.
```{r boldness-survival analysis for latency to enter the middle}
#etho = read.csv("/Users/kelseymccune/Documents/GitHub/Personality_BMAA/EthoData_updated.csv", header=T, sep=",", stringsAsFactors=F)
#etho$trial.time = 360
#etho$OLRE = seq_len(nrow(etho)) #column with observation-level random effect
#etho$scale.age = scale(etho$Age, scale = T, center = T)
#etho$FishName = as.factor(etho$FishName)
#etho$Treatment = as.factor(etho$Treatment)
#etho$Age[which(etho$Age == "15")]<-"14"

### Use LatencyZ2360 - which gives a ceiling value to those fish that never entered the center (10% of data) ###

############################################
# Survival analysis repeatability using rptRsurv function written by Shinichi Nakagawa and Kelsey (https://github.com/kelseybmccune/Time-to-Event_Repeatability/tree/main)

# Define the function
# missing values ignored

#' @title comxe_pval
#' @description This function calculates the p-value of the effect of the random effect in a coxme model. It also provides the p-value of the effect of the random effect using a bootstrapped method.
#' @param model A coxme model object
#' @param data The original data used to fit the model
#' @param boot Number of simulations to run to produce 95 percent confidence intervals for I2. Default is \code{NULL}, where only the point estimate is provided.
#' @return A vector of p-values
#' @author Shinichi Nakagawa - s.nakagawa@unsw.edu.au
#' @author etc

coxme_pval <- function(model, data, boot = NULL) {
  # Get the original data
  
  if(all(class(model) %in% c("coxme")) == FALSE) {stop("Sorry, you need to fit a coxme model of class coxme")}
  
  # I think we need to use get the dimension of the data

  response <- as.data.frame(model$y[,1:2])
  
  fixed_formula <- as.formula(model$formulaList$fixed)
  
  # fit the model without any random effects
  fit <- survival::coxph(as.formula(fixed_formula), data = data)
  # loglikelihood ratio test
  # this is p value of effect of taking all random effects
  pval<- anova(fit, model)$P[-1]
  names(pval) <- "liklihood_ratio_test"
  
  if(!is.null(boot)){
  
  # we need to use replicate to create many vectors of these - randomize the data
  orders <- replicate(boot, sample(1:nrow(response)))  
  
  fixed_formula <- as.character(fixed_formula)  
  random_formula <-  as.vector(as.character(model$formulaList$random))        
  formula <- as.formula(paste("Surv(new_time, new_status)", 
                           "~", 
                           fixed_formula[3], 
                           "+",
                           paste(random_formula, collapse = "+")))
  data2 <- data

  # randomizaton/permutation tests
  pb <- progress::progress_bar$new(total = boot,
                                 format = "Bootstrapping [:bar] :percent ETA: :eta",
                                 show_after = 0)

  # loop
  num <- length(summary(model)$random$variance)

  store <- matrix(NA, nrow = num, ncol = boot)

  # Loop over the number of bootstraps
  for (i in 1:boot) {
  # Permute the data

  data2$new_time <- response$time[orders[ ,i]]
  data2$new_status <- response$status[orders[ ,i]]

  # Fit the original coxme model
  temp  <- tryCatch(coxme(formula, data = data2))

  # get variance component
   store[ ,i] <- summary(temp)$random$variance

   pb$tick()
   Sys.sleep(1 / boot)

    }
   
  # getting the p value
   pval2 <- sapply(1:num, function(x) {
     sum(store[x,] > summary(model)$random$variance[x])/boot}
     )
   
   names(pval2) <- paste(rep("bootstrapped_pval", num), 1:num, sep = "_")
  }

  if(exists("pval2")) {
    
  res <- c(pval, pval2)
  return(res)
  
  } else {
  res <- pval
  return(res)
  }

}


#' @title coxme_icc_ci
#' @description This function calculates the 95 percent confidence interval for the intraclass correlation from the `coxme` objects.
#' @param model A coxme model object
#' @param upper.multiplier The multiplier for the upper bound of the confidence interval. Default is 10 (adjust to a higer value if the upper bound is not reached).
#' @return A vector of the lower, point estimate, and upper bounds of the 95 percent confidence interval for the intraclass correlation
#' @author Shinichi Nakagawa - s.nakagawa@unsw.edu.au
#' @author etc

coxme_icc_ci <- function(model, upper.multiplier = 10) {
  if(all(class(model) %in% c("coxme")) == FALSE)
    {stop("Sorry, you need to fit a coxme model of class coxme")} 
  if(any(length(summary(model)$random$variance) > 1)) {stop("Sorry. At the moment, we can only have a model with one random effect.")}
  
  # Define a sequence of variance values``
  # the length of the response
  n <- nrow(model$y)
  cut = 100
  
  var_point <- summary(model)$random$variance
  
  # based on this pdf: https://cran.r-project.org/web/packages/coxme/vignettes/coxme.pdf
  # upper CI is limited to var_point*(10*log(n)) - so this could fail
  estvar1 <- seq(0.00000000000001, var_point, length = cut)
  estvar2 <- seq(var_point, var_point*upper.multiplier, length = cut+1)[-1]
  estvar <- c(estvar1, estvar2)
  
  # Initialize a vector to store the log-likelihood values
  loglik <- double(cut)
  
  # Loop over the variance values
  for (i in seq_len(cut*2)) {
    # Fit a coxme model with fixed variance
    tfit <- update(model, vfixed = estvar[i])
    
    # Compute the log-likelihood
    loglik[i] <- 2 * diff(tfit$loglik)[1]
  }
  
  # Compute the threshold for the 95% confidence interval
  temp <-  as.numeric(2 * diff(model$loglik)[1]) - loglik
  
  # Find the variance values that correspond to the threshold
  # getting lower and upper CI using profile likelihood
  lower <- approx(temp[1:(cut)], sqrt(estvar[1:(cut)]), qchisq(.95, 1))$y
  upper <- approx(temp[(cut + 1):(2*cut)], sqrt(estvar[(cut + 1):(2*cut)]), qchisq(.95, 1))$y
  
  # Return the 95% confidence interval
  ICC_lower <- lower^2 / (lower^2 + pi^2 / 6)
  if (is.na(ICC_lower)) {
    ICC_lower <- 0
  }
  ICC_point <- var_point / (var_point + pi^2 / 6)
  ICC_upper <- upper^2 / (upper^2 + pi^2 / 6)
  names(ICC_lower) <- "lower"
  names(ICC_point) <- "ICC"
  names(ICC_upper) <- "upper"
  
  return(c(ICC_lower, ICC_point, ICC_upper))
}

############################################

library(coxme)
etho$event = ifelse(etho$LatencyZ2360 == 360,0,1)
b1 = coxme(Surv(LatencyZ2360,event)~Treatment + scale.age + Treatment*scale.age + (1|FishName), data = etho). # function can only handle 1 random effect
coxme_pval(b1,etho,boot=100) #  p < 0.01
coxme_icc_ci(b1, upper.multiplier = 10) # ICC = 0.09 (0.05-0.13)


```


```{r boldness - log transformed latency}
library(DHARMa)
library(lme4)

hist(etho$LatencyZ2360) # could be poisson
hist(log(etho$LatencyZ2360+1))

#Poisson 
simulationOutput <- simulateResiduals(fittedModel = glmer(round(LatencyZ2360) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch) + (1|Paternity), family = poisson, data=etho), n=500) 
#Gaussian
simulationOutput <- simulateResiduals(fittedModel = lmer(log(LatencyZ2360+1) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch) + (1|Paternity), data=etho), n=500)

plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor. 
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation.
#p.nb= 0.03 (under-dispersed), p.pois = 0.63, p.gaus = 0.9 
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p>0.05.
#p.nb=0.9, p.pois < 0.01, p.gaus < 0.01  (3% are zeros) ... something seems wrong here
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05.
#p.nb= 0.04, p.pois < 0.01, p.gaus= 0.11
plot(simulationOutput)


l1 = lmer(log(LatencyZ2360+1) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch) + (1|Paternity), data=etho) #full model
l2 = lmer(log(LatencyZ2360+1) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch), data=etho)
anova(l1,l2) #no difference, use simpler model (l2)
VarCorr(l2) #Random effects and residual variance

l3 = lmer(log(LatencyZ2360+1) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName), data=etho)
anova(l2,l3) #l2 is better

l4 = lmer(log(LatencyZ2360+1) ~ Treatment + scale.age + (1|FishName) + (1|Clutch), data=etho)
anova(l2,l4) #no difference, use simpler model (l4)

l5 = lmer(log(LatencyZ2360+1) ~ Treatment + scale.age + (1|Clutch), data=etho) # does FishName account for significant amount of variance?
anova(l5,l4) #model with both is better


l.rpt = rpt(log(LatencyZ2360+1) ~ Treatment + scale.age + (1|FishName) + (1|Clutch), datatype = "Gaussian", data=etho, grname = "FishName", nboot = 500, npermut = 500) #singular fit warning with or without Clutch
l.rpt
# R = 0.07 (0.03-0.13)
# p.LRT and p.permute < 0.01

plot(l.rpt, type = "permut")

```


### Boldness and treatment effects
```{r boldness & treatment}

summary(b1) # survival model
# significant effect of age

library(car)
summary(l4) # need to calculate p-values
Anova(l4, test="F")


library(nlme)
l4.nlme = lme(log(LatencyZ2360+1) ~ Treatment + scale.age, random = list(~ 1|FishName,
                                                                         ~ 1|Clutch), data=etho)
summary(l4.nlme)
# no treatment effects. Significant Age effect suggesting habituation (as fish experienced more trials/got older, latency to enter the center decreased)

# plot to visualize treatment effect
library(survminer)
b.plot.sfit = survfit(Surv(LatencyZ2360, event)~Treatment, data = etho)
bsurv.plot = ggsurvplot(b.plot.sfit, data = etho, fun = 'event', 
                       risk.table = F, pval = F, palette = c("black","#999999","red"), 
                       xlab = "Latency to enter the center (sec)", 
                       ylab = "Proportion", size = 1.5, legend = c(0.7,0.2))

b.plot.sfit2 = survfit(Surv(LatencyZ2360, event)~Age, data = etho)
bsurv.plot2 = ggsurvplot(b.plot.sfit2, data = etho, fun = 'event', 
                       risk.table = F, pval = F,  
                       xlab = "Latency to enter the center (sec)", 
                       ylab = "Proportion", size = 1.5, legend = c(0.7,0.2))


bol.plot = ggplot(etho, aes(x = Age, y = log(LatencyZ2360+1), color = Treatment))+
  geom_point(alpha = 0.7,size = 3) +
  geom_smooth(method = "lm") +
  theme_bw() +
  scale_x_continuous(limits=c(0,200),
                     breaks=c(14,21,49,77,105,133,161,189))+
  ylab("Latency to enter the center") + ggtitle("b) Boldness")
```
BMAA treatment was unrelated to the latency to enter the center (boldness). As individuals experience more trials, the latency to enter the center decreased, suggesting habituation to the experimental arena.



## Activity
Mobility is our measure of activity. This variable describes the percentage of pixel change between the current sample at the time (t) and previous sample (t-1) *this is detected in the subject only, not the full arena* (full arena pixel change aka "activity" described by EthoVision) ; ranges from 0 - 100%. Mobility depends on the size of subject only, not on the arena size; a small fish results in a small number of pixels that change, therefore small movements may result in high change.

Because we are not using variance in turning angle as a measure of exploration anymore, no need to include it as a covariate.
```{r activity- mobility}
#etho = read.csv("/Users/kelseymccune/Documents/GitHub/Personality_BMAA/EthoData_updated.csv", header=T, sep=",", stringsAsFactors=F)
#etho$FishName = as.factor(etho$FishName)
#etho$Treatment = as.factor(etho$Treatment)
#etho$Age[which(etho$Age == 15)]<-14
#etho$Age = as.numeric(etho$Age)
#etho$scale.age = scale(etho$Age, scale = T, center = T)

library(DHARMa)
library(lme4)
library(rptR)

hist(etho$Mean.Mobility) # looks good

#Gaussian
simulationOutput <- simulateResiduals(fittedModel = lmer(log(Mean.Mobility+1) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch) + (1|Paternity), data=etho), n=500)
#Poisson 
simulationOutput <- simulateResiduals(fittedModel = glmer(round(Mean.Mobility) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch) + (1|Paternity), family = poisson, data=etho), n=500) 

plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor. 
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation.
#p.g = 0.94 , p.p < 0.01
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p>0.05.
#p.g = 1 , p.p = 0.79
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05.
#p.g < 0.01 , p.p < 0.01

#the log(Mean.Mobility+1) brings the uniformity p-val = 0.0445 (from 6.848e-08). Going with log
plot(simulationOutput)

m1 = lmer(log(Mean.Mobility+1) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch) + (1|Paternity), data=etho) #full model
m2 = lmer(log(Mean.Mobility+1) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName) + (1|Clutch), data=etho)
anova(m1,m2) #no difference, use simpler model (m2)

m3 = lmer(log(Mean.Mobility+1) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName), data=etho)
anova(m2,m3) #m2 is better

m4 = lmer(log(Mean.Mobility+1) ~ Treatment + scale.age + (1|FishName) + (1|Clutch), data=etho)
anova(m2,m4) #no difference, use simpler model (m4)

m5 = lmer(log(Mean.Mobility+1) ~ Treatment + scale.age + (1|Clutch), data=etho) # does FishName account for significant amount of variance?
anova(m5,m4) #m4 is better - accounts for somethin!

m6 = lmer(log(Mean.Mobility+1) ~ Treatment + scale.age + (1|FishName), data=etho) # does Clutch account for significant amount of variance?
anova(m4,m6) #m4 is better - accounts for somethin!


m.rpt = rpt(log(Mean.Mobility+1) ~ Treatment + scale.age + (1|FishName) + (1|Clutch), datatype = "Gaussian", data=etho, grname = c("FishName","Clutch"), nboot = 500, npermut = 500) #singular fit warning with or without Clutch
m.rpt
# R = 0.13 (0.07-0.18)
# p.LRT and p.permute < 0.01

plot(m.rpt, type = "permut")

theta <- getME(m4, "theta")
diag.element <- getME(m4, "lower")==0
which(theta[diag.element]<1e-5) #looks like clutch and fishname are important

```

### Activity and treatment effects
```{r activity & treatment}

m4 = lmerTest::lmer(log(Mean.Mobility+1) ~ Treatment + Age + (1|FishName) + (1|Clutch), data=etho)
summary(m4)
Anova(m4) # global effect of Treatment and age

library(emmeans)
c1 = emmeans(m4, pairwise ~ Treatment,type="response") 
plot(c1$emmeans) 
c1$contrasts %>%
     summary(infer = TRUE)
# Treatment 5 significantly less active than Treatment 25. Not different compared to control fish.
## Age: B = -0.10, p = 0; As age/trial number increases, activity level decreases



# plot to visualize treatment effect
act.plot = ggplot(etho, aes(x = Age, y = log(Mean.Mobility+1), color = Treatment))+
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm") +
  theme_bw() +
  scale_x_continuous(limits=c(0,200),
                     breaks=c(14,21,49,77,105,133,161,189))+
  ylab("Mean Mobility") + ggtitle("c) Activity")
```
Treatment affects activity level, but the relationship varies by amount of treatment. Treatment 5 fish are significantly less active than Treatment 25 fish. Neither Treatment is significantly different from Control fish.

```{r combind figure}
comb.plot = ggarrange(exp.plot+rremove("xlab"),bol.plot+rremove("xlab"),act.plot,
                 common.legend = T, legend = "right",
                 font.label=list(color="black",size=22),
                 nrow = 3,ncol = 1,align = "hv")

comb.plot
```

## Why are repeatability values so low?

```{r visualizing variance components}
#Cumulative duration in the center
ggplot(etho, aes(x = reorder(FishName,CumDur.Z2,mean), y = log(CumDur.Z2+1), color = Treatment)) +
  facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank())

ggplot(etho, aes(x = as.factor(as.numeric(Age)), y = log(CumDur.Z2+1), color = Treatment)) +
  geom_boxplot() +
  theme_classic()

#Latency to enter the center
ggplot(etho, aes(x = reorder(FishName,LatencyZ2360,mean), y = LatencyZ2360, color = Treatment)) +
  facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank())

ggplot(etho, aes(x = as.factor(as.numeric(Age)), y = LatencyZ2360, color = Treatment)) +
  geom_boxplot() +
  theme_classic()

#Mobility
ggplot(etho, aes(x = reorder(FishName,Mean.Mobility,mean), y = log(Mean.Mobility+1), color = Treatment)) +
  facet_wrap(~Treatment) +
  geom_boxplot() +
  theme_classic() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank())

ggplot(etho, aes(x = as.factor(as.numeric(Age)), y = log(Mean.Mobility+1), color = Treatment)) +
  geom_boxplot() +
  theme_classic()

##Distribution of values look similar across groups

# Look at the variance components to see whether within-individual variance is large and/or between individual variance is small.
## Duration in center (exploration)
rptB = rpt(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age + (1|FishName), datatype = "Poisson", ratio = F, data=etho, grname = c("FishName","Residual"), nboot = 100, npermut = 100)
## MCMCglmm estimates:
mean(mc1$VCV[,"FishName"]) 
mean(mc1$VCV[,"units"])
### Within-individual (residual) variance (1.84) is much larger than between individual (0.26)

## Latency to enter center (boldness)
l.rpt = rpt(log(LatencyZ2360+1) ~ Treatment + scale.age + (1|FishName) + (1|Clutch), datatype = "Gaussian", ratio = F, data=etho, grname = c("FishName","Residual"), nboot = 100, npermut = 100)
print(l.rpt)
### Within-individual variance (2.27) is much larger than between individual (0.19)

## Mobility (activity)
m.rpt = rpt(Mean.Mobility ~ Treatment + scale.age + (1|FishName) + (1|Clutch), datatype = "Gaussian", ratio = F, data=etho, grname = c("FishName","Clutch","Residual"), nboot = 100, npermut = 100)
print(m.rpt)
### Within-individual variance (27.6) is much larger than between individual (3.81) or between clutch (1.63) variance

# Is residual variance different for each treatment group?
## Exploration
mc1 = MCMCglmm(round(CumDur.Z2) ~ Treatment + scale.age + Treatment*scale.age, random = ~FishName, family = "poisson", data = etho,
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000) #all data combined with Treatment effect
mc0 = MCMCglmm(round(CumDur.Z2) ~ scale.age, random = ~FishName, family = "poisson", data = etho[which(etho$Treatment == "0"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000) #Control treatment
mean(mc0$VCV[,"units"]) # 1.44
repeat0 <- mc0$VCV[,"FishName"]/(mc0$VCV[,"FishName"]+mc0$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat0) # Control Repeatability: 0.16
HPDinterval(repeat0, 0.95) # 0.04 - 0.29

mc5 = MCMCglmm(round(CumDur.Z2) ~ scale.age, random = ~FishName, family = "poisson", data = etho[which(etho$Treatment == "5"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000) #Treatment 5
mean(mc5$VCV[,"units"]) # 2.38
repeat5 <- mc5$VCV[,"FishName"]/(mc5$VCV[,"FishName"]+mc5$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat5) # Treatment 5 Repeatability: 0.05
HPDinterval(repeat5, 0.95) # 0.0001 - 0.14

mc25 = MCMCglmm(round(CumDur.Z2) ~ scale.age, random = ~FishName, family = "poisson", data = etho[which(etho$Treatment == "25"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000) # Treatment 25
mean(mc25$VCV[,"units"]) # 1.98
repeat25 <- mc25$VCV[,"FishName"]/(mc25$VCV[,"FishName"]+mc25$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat25) # Treatment 25 Repeatability: 0.14
HPDinterval(repeat25, 0.95) # 0.01 - 0.26


## Boldness
prior = list(R=list(R1=list(V=1,nu=0.002)), G=list(G1=list(V=1,nu=0.002),G2=list(V=1,nu=0.002)))
mb0 = MCMCglmm(log(LatencyZ2360+1) ~ scale.age,random = ~FishName+Clutch, family = "gaussian", data = etho[which(etho$Treatment == "0"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
mean(mb0$VCV[,"units"]) # 2.24
repeat0 <- mb0$VCV[,"FishName"]/(mb0$VCV[,"FishName"]+mb0$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat0) # Control Repeatability: 0.09
HPDinterval(repeat0, 0.95) # 0.0002 - 0.17

mb5 = MCMCglmm(log(LatencyZ2360+1) ~ scale.age,random = ~FishName+Clutch, family = "gaussian", data = etho[which(etho$Treatment == "5"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
mean(mb5$VCV[,"units"]) # 2.65
repeat5 <- mb5$VCV[,"FishName"]/(mb5$VCV[,"FishName"]+mb5$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat5) # Treatment 5 Repeatability: 0.04
HPDinterval(repeat5, 0.95) # 0.0001 - 0.12

mb25 = MCMCglmm(log(LatencyZ2360+1) ~ scale.age,random = ~FishName+Clutch, family = "gaussian", data = etho[which(etho$Treatment == "25"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
mean(mb25$VCV[,"units"]) # 2.15
repeat25 <- mb25$VCV[,"FishName"]/(mb25$VCV[,"FishName"]+mb25$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat25) # Treatment 25 Repeatability: 0.06
HPDinterval(repeat25, 0.95) # 0.0001 - 0.14


## Activity
ma0 = MCMCglmm(Mean.Mobility ~ scale.age,random = ~FishName+Clutch, family = "gaussian", data = etho[which(etho$Treatment == "0"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
mean(ma0$VCV[,"units"]) # 26.21
mean(ma0$VCV[,"FishName"]) # 3.56
repeat0 <- ma0$VCV[,"FishName"]/(ma0$VCV[,"FishName"]+ma0$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat0) # Control Repeatability: 0.12
HPDinterval(repeat0, 0.95) # 0.04 - 0.22

ma5 = MCMCglmm(Mean.Mobility ~ scale.age,random = ~FishName+Clutch, family = "gaussian", data = etho[which(etho$Treatment == "5"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
mean(ma5$VCV[,"units"]) # 25.53
mean(ma5$VCV[,"FishName"]) # 3.13
repeat5 <- ma5$VCV[,"FishName"]/(ma5$VCV[,"FishName"]+ma5$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat5) # Treatment 5 Repeatability: 0.11
HPDinterval(repeat5, 0.95) # 0.0001 - 0.21

ma25 = MCMCglmm(Mean.Mobility ~ scale.age,random = ~FishName+Clutch, family = "gaussian", data = etho[which(etho$Treatment == "25"),],
               verbose=F, prior=prior, nitt=63000, thin=20, burnin=5000)
mean(ma25$VCV[,"units"]) # 32.11
mean(ma25$VCV[,"FishName"]) # 5.38
repeat25 <- ma25$VCV[,"FishName"]/(ma25$VCV[,"FishName"]+ma25$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeat25) # Treatment 25 Repeatability: 0.14
HPDinterval(repeat25, 0.95) # 0.04 - 0.25

```
Residual variance is generally much higher than among-individual variance. In particular, the Treatment 5 group seems to have lower repeatability values and wider confidence intervals than the other two groups.


## Behavioral Syndromes
Using the tutorial/supplemental material from Houslay & Wilson 2017: Avoiding the misuse of BLUP in behavioral ecology https://tomhouslay.files.wordpress.com/2017/02/indivvar_mv_tutorial_mcmcglmm.pdf
```{r behav syndrome}
#etho = read.csv("/Users/kelseymccune/Documents/GitHub/Personality_BMAA/EthoData_updated.csv", header=T, sep=",", stringsAsFactors=F)
#etho$FishName = as.factor(etho$FishName)
#etho$Treatment = as.factor(etho$Treatment)
#etho$Age[which(etho$Age == 15)]<-14
#etho$Age = as.numeric(etho$Age)
#etho$scale.age = scale(etho$Age, scale = T, center = T)

library(MCMCglmm)

#uninformative prior for a model with 3 DVs, one random effect and two fixed effects
prior_mltvar = list(R = list(V = diag(3), nu = 1.002),
            G = list(G1 = list(V = diag(3), nu = 3,
            alpha.mu = rep(0,3),
            alpha.V = diag(25^2,3,3))))

#multivariate model for our 3 variables (Mean.Mobility, round(CumDur.Z2), log(LatencyZ2360+1)
# takes a long time to run!
mlt.var = MCMCglmm(cbind(Mean.Mobility, round(CumDur.Z2), log(LatencyZ2360+1)) ~ trait-1 +
            trait:scale.age +
            trait:Treatment,
            random =~ us(trait):FishName,
            rcov =~ us(trait):units,
            family = c("gaussian","poisson","gaussian"),
            prior = prior_mltvar,
            nitt=420000,
            burnin=8000,
            thin=100,
            verbose = TRUE,
            data = etho)

plot(mlt.var) # all looks pretty good
autocorr(mlt.var$Sol) # converged
autocorr(mlt.var$VCV) # converged
summary(mlt.var) # G-structure is DV variance and co-variances

# Checking that repeatability estimates are similar:
## Mean.Mobility
rpt.mob <- mlt.var$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"]/(    # between individual variation
mlt.var$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"] + 
mlt.var$VCV[,"traitMean.Mobility:traitMean.Mobility.units"]   #between individual variation + Residual variation
)
mean(rpt.mob) # 0.16 (higher than rpt)
HPDinterval(rpt.mob) # 0.11-0.22
plot(rpt.mob)

## CumDur.Z2
rpt.dur <- mlt.var$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]/(    # between individual variation
mlt.var$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"] + 
mlt.var$VCV[,"traitCumDur.Z2:traitCumDur.Z2.units"]   #between individual variation + Residual variation
)
mean(rpt.dur) # 0.12 (the same as MCMCglmm above)
HPDinterval(rpt.dur) # 0.06-0.18
plot(rpt.dur)

## LatencyZ2360
rpt.lat <- mlt.var$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"]/(    # between individual variation
mlt.var$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"] + 
mlt.var$VCV[,"traitLatencyZ2360:traitLatencyZ2360.units"]   #between individual variation + Residual variation
)
mean(rpt.lat) # 0.11 (higher than rpt)
HPDinterval(rpt.lat) # 0.06-0.16
plot(rpt.lat)


# Correlations between 2 traits
## Mobility/Duration
cor_MobDur <- mlt.var$VCV[,"traitMean.Mobility:traitCumDur.Z2.FishName"]/
(sqrt(mlt.var$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"])*
sqrt(mlt.var$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]))
mean(cor_MobDur) # 0.09
HPDinterval(cor_MobDur) # -0.23-0.43 ...crosses zero so non-significant correlation
plot(cor_MobDur)

## Mobility/Latency
cor_MobLat <- mlt.var$VCV[,"traitMean.Mobility:traitLatencyZ2360.FishName"]/
(sqrt(mlt.var$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"])*
sqrt(mlt.var$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"]))
mean(cor_MobLat) # -0.77
HPDinterval(cor_MobLat) # -0.96 - -0.60 ...does NOT cross zero, so significant correlation
plot(cor_MobLat)

## Latency/Duration
cor_LatDur <- mlt.var$VCV[,"traitLatencyZ2360:traitCumDur.Z2.FishName"]/
(sqrt(mlt.var$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"])*
sqrt(mlt.var$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]))
mean(cor_LatDur) # -0.34
HPDinterval(cor_LatDur) # -0.65 - -0.02 ...does NOT cross zero, so significant correlation
plot(cor_LatDur)


# Visualizing
## Correlation plot
df_cors <- data.frame(Traits = c("Activity,Exploration",
                                 "Activity,Boldness",
                                 "Boldness, Exploration"),
                      Estimate = c(mean(cor_MobDur),
                                   mean(cor_MobLat),
                                   mean(cor_LatDur)),
                      Lower = c(HPDinterval(cor_MobDur)[,"lower"],
                                HPDinterval(cor_MobLat)[,"lower"],
                                HPDinterval(cor_LatDur)[,"lower"]),
                      Upper = c(HPDinterval(cor_MobDur)[,"upper"],
                                HPDinterval(cor_MobLat)[,"upper"],
                                HPDinterval(cor_LatDur)[,"upper"]))

ggplot(df_cors, aes(x = Traits, y = Estimate)) +
       geom_pointrange(aes(ymin = Lower, ymax = Upper)) +
       geom_hline(yintercept = 0, linetype = "dotted", alpha = 0.3) +
       scale_x_discrete(limits = c("Activity,Exploration","Activity,Boldness","Boldness, Exploration")) +
       labs(x = "Trait combinations",y = "Correlation (Estimate +/- 95% CIs)") +
       ylim(-1,1) + coord_flip() +
       theme_classic()


```

Boldness and exploration are negatively correlated, but that has to do with the fact that boldness is quantified as a latency. More exploratory individuals (spent more time in the center), had lower latencies to enter the center (i.e. more bold). Similarly, more active individuals had shorter latencies to enter the center. The propensity to show higher activity was not significantly correlated with the amount of time spent in the center.

### Do behavioral syndromes vary by treatment level?
```{r BS by treatment}
library(MCMCglmm)

# 3 separate multivariate models for contol, treatment 5 and treatment 25:
##uninformative prior for a model with 3 DVs, one random effect and one fixed effects
prior_mltvar = list(R = list(V = diag(3), nu = 1.002),
            G = list(G1 = list(V = diag(3), nu = 3,
            alpha.mu = rep(0,3),
            alpha.V = diag(25^2,3,3))))

t0.bs = MCMCglmm(cbind(Mean.Mobility, round(CumDur.Z2), log(LatencyZ2360+1)) ~ trait-1 +
            trait:scale.age,
            random =~ us(trait):FishName,
            rcov =~ us(trait):units,
            family = c("gaussian","poisson","gaussian"),
            prior = prior_mltvar,
            nitt=420000,
            burnin=8000,
            thin=100,
            verbose = TRUE,
            data = etho[which(etho$Treatment == "0"),])

t5.bs = MCMCglmm(cbind(Mean.Mobility, round(CumDur.Z2), log(LatencyZ2360+1)) ~ trait-1 +
            trait:scale.age,
            random =~ us(trait):FishName,
            rcov =~ us(trait):units,
            family = c("gaussian","poisson","gaussian"),
            prior = prior_mltvar,
            nitt=420000,
            burnin=8000,
            thin=100,
            verbose = TRUE,
            data = etho[which(etho$Treatment == "5"),])

t25.bs = MCMCglmm(cbind(Mean.Mobility, round(CumDur.Z2), log(LatencyZ2360+1)) ~ trait-1 +
            trait:scale.age,
            random =~ us(trait):FishName,
            rcov =~ us(trait):units,
            family = c("gaussian","poisson","gaussian"),
            prior = prior_mltvar,
            nitt=420000,
            burnin=800,
            thin=100,
            verbose = TRUE,
            data = etho[which(etho$Treatment == "25"),])

# From the variance components of the modles calculate the correlation among individuals for each pair of variables in each treatment group
## Control (T0)
### Mobility/Duration
t0.cor_MobDur <- t0.bs$VCV[,"traitMean.Mobility:traitCumDur.Z2.FishName"]/
(sqrt(t0.bs$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"])*
sqrt(t0.bs$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]))
### Mobility/Latency
t0.cor_MobLat <- t0.bs$VCV[,"traitMean.Mobility:traitLatencyZ2360.FishName"]/
(sqrt(t0.bs$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"])*
sqrt(t0.bs$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"]))
### Latency/Duration
t0.cor_LatDur <- t0.bs$VCV[,"traitLatencyZ2360:traitCumDur.Z2.FishName"]/
(sqrt(t0.bs$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"])*
sqrt(t0.bs$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]))

## Treatment 5 (T5)
### Mobility/Duration
t5.cor_MobDur <- t5.bs$VCV[,"traitMean.Mobility:traitCumDur.Z2.FishName"]/
(sqrt(t5.bs$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"])*
sqrt(t5.bs$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]))
### Mobility/Latency
t5.cor_MobLat <- t5.bs$VCV[,"traitMean.Mobility:traitLatencyZ2360.FishName"]/
(sqrt(t5.bs$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"])*
sqrt(t5.bs$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"]))
### Latency/Duration
t5.cor_LatDur <- t5.bs$VCV[,"traitLatencyZ2360:traitCumDur.Z2.FishName"]/
(sqrt(t5.bs$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"])*
sqrt(t5.bs$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]))

## Treatment 25 (T25)
### Mobility/Duration
t25.cor_MobDur <- t25.bs$VCV[,"traitMean.Mobility:traitCumDur.Z2.FishName"]/
(sqrt(t25.bs$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"])*
sqrt(t25.bs$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]))
### Mobility/Latency
t25.cor_MobLat <- t25.bs$VCV[,"traitMean.Mobility:traitLatencyZ2360.FishName"]/
(sqrt(t25.bs$VCV[,"traitMean.Mobility:traitMean.Mobility.FishName"])*
sqrt(t25.bs$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"]))
### Latency/Duration
t25.cor_LatDur <- t25.bs$VCV[,"traitLatencyZ2360:traitCumDur.Z2.FishName"]/
(sqrt(t25.bs$VCV[,"traitLatencyZ2360:traitLatencyZ2360.FishName"])*
sqrt(t25.bs$VCV[,"traitCumDur.Z2:traitCumDur.Z2.FishName"]))


# Visualizing
## Correlation plot
t.df_cors <- data.frame(Traits = c("Activity,Exploration","Activity,Exploration","Activity,Exploration",
                                 "Activity,Boldness","Activity,Boldness","Activity,Boldness",
                                 "Boldness, Exploration","Boldness, Exploration","Boldness, Exploration"),
                      Treatment = c("Control","T5","T25",
                                    "Control","T5","T25",
                                    "Control","T5","T25"),  
                      Estimate = c(mean(t0.cor_MobDur),mean(t5.cor_MobDur),mean(t25.cor_MobDur),
                                   mean(t0.cor_MobLat),mean(t5.cor_MobLat),mean(t25.cor_MobLat),
                                   mean(t0.cor_LatDur),mean(t5.cor_LatDur),mean(t25.cor_LatDur)),
                      Lower = c(HPDinterval(t0.cor_MobDur)[,"lower"],HPDinterval(t5.cor_MobDur)[,"lower"],HPDinterval(t25.cor_MobDur)[,"lower"],
                                HPDinterval(t0.cor_MobLat)[,"lower"],HPDinterval(t5.cor_MobLat)[,"lower"],HPDinterval(t25.cor_MobLat)[,"lower"],
                                HPDinterval(t0.cor_LatDur)[,"lower"],HPDinterval(t5.cor_LatDur)[,"lower"],HPDinterval(t25.cor_LatDur)[,"lower"]),
                      Upper = c(HPDinterval(t0.cor_MobDur)[,"upper"],HPDinterval(t5.cor_MobDur)[,"upper"],HPDinterval(t25.cor_MobDur)[,"upper"],
                                HPDinterval(t0.cor_MobLat)[,"upper"],HPDinterval(t5.cor_MobLat)[,"upper"],HPDinterval(t25.cor_MobLat)[,"upper"],
                                HPDinterval(t0.cor_LatDur)[,"upper"],HPDinterval(t5.cor_LatDur)[,"upper"],HPDinterval(t25.cor_LatDur)[,"upper"]))

ggplot(t.df_cors, aes(x = Traits, y = Estimate, color = Treatment)) +
       geom_pointrange(aes(ymin = Lower, ymax = Upper),position=position_dodge(width=0.5)) +
       geom_hline(yintercept = 0, linetype = "dotted", alpha = 0.3) +
       scale_x_discrete(limits = c("Activity,Exploration","Activity,Boldness","Boldness, Exploration")) +
       labs(x = "Trait combinations",y = "Correlation (Estimate +/- 95% CIs)") +
       ylim(-1,1) + coord_flip() +
       theme_classic()

```
No difference in behavioral syndromes by Treatment because all 95% CIs overlap among the treatment groups. However, the decreased sample size led to the boldness:exploration correlation becoming statistically nonsignificant.



